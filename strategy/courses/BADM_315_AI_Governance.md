# BADM 315: AI Governance & Responsible Business

**Level:** 300 (Junior/Senior)
**Credits:** 3
**Semester:** Fall 2026 (Pilot)
**Prerequisites:** None (BADM 210 recommended)
**Track:** Human Centric AI
**L-C-E Target:** Literacy → Competency

---

## Course Overview

As AI systems increasingly influence business decisions—from hiring to credit decisions to content moderation—organizations face unprecedented governance challenges. This course prepares business leaders to navigate the ethical, regulatory, and operational dimensions of AI deployment.

**Core Question:** How do responsible organizations design, implement, and oversee AI systems in ways that create stakeholder value while minimizing harm?

### Learning Outcomes

Upon completion, students will be able to:

**Literacy Level:**
1. Identify key AI governance concerns including bias, fairness, transparency, and accountability
2. Explain regulatory requirements (EU AI Act, sector-specific US rules, GDPR)
3. Recognize different organizational governance structures and oversight mechanisms

**Competency Level:**
1. Apply ethical frameworks (consequentialist, deontological, virtue ethics) to AI decisions
2. Evaluate organizational AI governance policies for adequacy and alignment with values
3. Design accountability mechanisms and oversight structures for AI systems
4. Assess bias and fairness issues in business-critical AI systems

### Who Should Take This Course

- **BADM Majors:** Required for students seeking AI leadership roles
- **Finance/Accounting Majors:** Critical for regulatory and compliance roles
- **Cross-discipline:** Open to all undergraduates interested in responsible AI

---

## Course Schedule

### **Week 1-2: Foundations of AI Ethics**

#### Week 1: AI Ethics Fundamentals
**Topics:**
- What is AI ethics? (Definition, history, why it matters now)
- Three ethical frameworks:
  - **Consequentialist:** Outcomes-focused (maximize benefit, minimize harm)
  - **Deontological:** Rules-based (duty to fairness, transparency, rights)
  - **Virtue Ethics:** Character-based (integrity, trustworthiness, justice)
- Stakeholder perspectives (customers, employees, communities, shareholders)

**Readings:**
- Jobin et al. (2019). "The Global Landscape of AI Ethics Guidelines" *Nature Machine Intelligence*
- Virginia Dignum. (2019). "Responsible Artificial Intelligence" (Chapter 1: Ethics for AI)

**In-Class Activity:**
- Case: Facebook's Cambridge Analytica scandal
  - What ethical frameworks apply?
  - Who are stakeholders?
  - What could have been done differently?

**Assessment:** Reflection paper (1-2 pages): "Which ethical framework resonates most for you? Why?"

---

#### Week 2: Bias, Fairness, and Discrimination in AI
**Topics:**
- Defining bias in AI systems (data bias, algorithm bias, human bias)
- Types of fairness (demographic parity, equalized odds, individual fairness)
- When fairness metrics conflict (the fairness-accuracy tradeoff)
- Real-world impacts: hiring, lending, criminal justice, healthcare

**Readings:**
- Buolamwini & Buolamwini. (2018). "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification" (10-min video + paper)
- Corbett-Davies et al. (2016). "Algorithmic Fairness and the Impossibility Results" *Journal of Political Philosophy*

**Case Studies:**
- Amazon's bias hiring tool (recruited women at lower rates)
- Apple's credit card bias (offered lower limits to women)
- COMPAS recidivism algorithm (disparate impact on Black defendants)

**In-Class Activity:**
- Workshop: Audit a real business AI system for bias
- Identify data sources, potential confounds, protected characteristics
- Recommend fairness metrics and monitoring

**Assessment:** Group case analysis (3-4 pages): Identify bias sources and propose fairness framework

---

### **Week 3-4: Transparency, Explainability, and Accountability**

#### Week 3: Explainability and Transparency
**Topics:**
- Why explainability matters (trust, debugging, compliance)
- Black box vs. interpretable models
- Explainability techniques:
  - LIME (Local Interpretable Model-Agnostic Explanations)
  - SHAP (SHapley Additive exPlanations)
  - Attention mechanisms
- Limits of explainability (Goodman's critique)
- Transparency vs. secrecy (trade-offs)

**Readings:**
- Ribeiro et al. (2016). "Why Should I Trust You? Explaining the Predictions of Any Classifier" (LIME)
- Goodman & Flaxman. (2016). "European Union Regulations on Algorithmic Decision Making" *arXiv* (accountability section)

**In-Class Activity:**
- Live demo: LIME tool applied to real ML model
- Debate: "Should all AI systems be explainable?"
- Small group: Design transparency report for a business AI system

**Assessment:** Written response (2 pages): "When is explainability essential vs. optional?"

---

#### Week 4: Accountability Structures
**Topics:**
- Who is responsible? (Developers? Companies? Users? Society?)
- Accountability mechanisms:
  - Internal (ethics review boards, impact assessments)
  - Contractual (vendor liability, SLAs)
  - Legal (liability frameworks, insurance)
  - Social (reputation, stakeholder pressure)
- Liability gaps and challenges
- Building an organizational AI ethics function

**Readings:**
- Rességuier & Rodrigues. (2020). "AI Ethics Should Not Remain Toothless!" *Science and Engineering Ethics*
- Mittelstadt. (2017). "From Values to Value: Algorithmic Governance and Fairness" *European Journal of Risk Regulation*

**Case Study:**
- Zillow Zestimate bias: Who bears responsibility and cost?
- Twitter's algorithm amplifying political polarization

**In-Class Activity:**
- Design an AI Governance Charter for a fictional company
- Include: oversight structure, decision rights, appeal process, stakeholder engagement

**Assessment:** Governance charter draft (4-5 pages)

---

### **Week 5-6: Regulatory Landscape**

#### Week 5: EU AI Act and International Frameworks
**Topics:**
- EU AI Act (2024): structure, risk levels, compliance requirements
- GDPR implications for AI (data rights, algorithmic transparency)
- Fair Credit Reporting Act (FCRA) in US context
- Sector-specific regulations (finance, healthcare, autonomous vehicles)
- International coordination and divergence

**Readings:**
- EU AI Act (2024) - Article 1-10 (30 min read, focus on risk classification)
- Summary: "The AI Act Explained" *PolicyBrief* from Brookings (10 pages)

**In-Class Activity:**
- Regulatory mapping: Classify a real AI system under EU AI Act
- Identify required documentation, testing, monitoring
- Cost-benefit analysis: Compliance investment vs. risk

**Assessment:** Compliance brief (3 pages): "Is this system high-risk under EU AI Act?"

---

#### Week 6: Practical Compliance and Due Diligence
**Topics:**
- AI governance in practice (Google, Microsoft, Meta frameworks)
- Impact assessments (DPIA, AIDA, etc.)
- Due diligence processes for AI vendors
- Documentation and audit trails
- Scenario: Regulatory enforcement (FTC, state AGs)

**Readings:**
- Google's AI Principles and governance framework (white paper)
- Framework: "AI Impact Assessment" *Centre for Data Ethics and Innovation*

**Case Study:**
- FTC settlement with Vonage (robocalls with AI voice cloning)
- CFPB enforcement on algorithmic bias in lending

**In-Class Activity:**
- Vendor due diligence exercise
- Review AI system procurement checklist
- Prepare compliance documentation

**Assessment:** Vendor evaluation memo (2-3 pages)

---

### **Week 7-9: Strategic AI Governance Case Studies**

#### Week 7: Case Study 1 - Content Moderation at Scale
**Topics:**
- How platforms (Meta, YouTube, TikTok) use AI for moderation
- Challenges: culture, context, languages, false positives
- Regulatory pressure (Digital Services Act, Online Safety Bill)
- Stakeholder voices (creators, users, society)

**Readings:**
- "The Unreasonable Effectiveness of Moderation at Scale" *Meta Tech Blog*
- Center for Internet and Society: Content Moderation case studies

**In-Class Activity:**
- Mock review: Evaluate platform moderation appeals
- Debate: "Should AI or humans have final say on content?"
- Design: Transparent moderation governance system

**Assessment:** Policy brief (3-4 pages): "Governance framework for platform moderation"

---

#### Week 8: Case Study 2 - AI in Hiring and HR
**Topics:**
- Talent acquisition AI (resume screening, interview analysis)
- Performance management AI
- Bias risks (protected characteristics, historical discrimination)
- Fairness metrics specific to HR
- Employee surveillance and privacy

**Readings:**
- HireVue ethics response and facial analysis bias research
- Harvard Business Review: "Why Diversity Programs Fail and AI Could Help" (ethical hiring)

**In-Class Activity:**
- Audit real hiring AI systems
- Identify bias sources (training data, protected characteristics, feature engineering)
- Design fairness framework and monitoring dashboard

**Assessment:** Hiring AI audit (4-5 pages) with recommendations

---

#### Week 9: Case Study 3 - AI in Financial Services
**Topics:**
- Algorithmic trading and market stability
- Credit scoring and lending discrimination
- Fraud detection systems
- Insurance pricing and discrimination
- Regulatory scrutiny (CFPB, SEC, FinCEN)

**Readings:**
- CFPB guidance: "Algorithmic Discrimination in Consumer Finance"
- Khandani et al. "Machine Learning and the Mortgage Crisis" *Journal of Financial Economics*

**In-Class Activity:**
- Analyze credit scoring algorithm for disparate impact
- Design fairness test and corrective actions
- Prepare compliance documentation

**Assessment:** Financial services governance case (4-5 pages)

---

### **Week 10-12: Capstone Projects**

#### Week 10: Capstone Project Workshop
**Topics:**
- Capstone project requirements
- Governance framework design process
- Stakeholder engagement techniques
- Writing effective governance documents

**In-Class Activity:**
- Project kick-off for student teams
- Peer review of project proposals
- Industry expert panel discussion

---

#### Week 11: Student Capstone Presentations (Part 1)
**Project Requirements:**

Students work in teams of 3-4 to design a comprehensive AI governance framework for a real or fictional business scenario.

**Deliverables:**
1. **Framework Document (8-10 pages):**
   - Executive Summary
   - Company AI Strategy & Use Cases
   - Ethical Considerations & Stakeholder Analysis
   - Regulatory Compliance Roadmap
   - Governance Structure (Decision-making, oversight, escalation)
   - Risk Assessment & Mitigation
   - Fairness & Bias Monitoring Plan
   - Transparency & Accountability Mechanisms
   - Implementation Timeline

2. **Governance Board Presentation (15 minutes)**
   - Pitch to fictional board of directors
   - Key risks and mitigation
   - Resource requirements
   - Success metrics

**Evaluation Criteria:**
- Completeness (all required components)
- Stakeholder analysis depth
- Regulatory awareness and specificity
- Practical feasibility
- Clarity and persuasiveness

---

#### Week 12: Student Capstone Presentations (Part 2) + Reflection

**In-Class Activity:**
- Remaining team presentations
- Peer feedback and questions
- Industry mentor feedback
- Reflection assignment

**Reflection Assignment:**
- What surprised you about AI governance?
- How will you apply this knowledge in your career?
- What questions remain?

---

## Assessment & Grading

| Component | Weight | Due Date |
|-----------|--------|----------|
| Weekly Reflections (5 × 2%) | 10% | Ongoing |
| Case Study Analyses (3 × 8%) | 24% | Weeks 4, 6, 9 |
| Regulatory Compliance Memo | 12% | Week 6 |
| Midterm: Governance Charter | 14% | Week 4 |
| Capstone Project Framework | 20% | Week 11 |
| Capstone Presentation | 15% | Weeks 11-12 |
| Class Participation | 5% | Ongoing |

**Grading Scale:**
- A: 90-100
- B: 80-89
- C: 70-79
- D: 60-69
- F: <60

---

## Required Resources

### Textbooks
- Dignum, V. (2019). *Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way*
- O'Neil, C. (2016). *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*

### Primary Sources
- EU AI Act (2024) - full text + guidance documents
- GDPR (Articles relevant to algorithmic decision-making)
- FTC Algorithmic Transparency guidance
- Company governance frameworks (Google, Microsoft, Meta, JPMorgan)

### Tools & Platforms
- LIME/SHAP for explainability (Python tools)
- Bias testing frameworks (Aequitas, Fairness Toolkit)
- Optional: IBM Fairness 360, Google What-If Tool

### Guest Speakers (TBD)
- AI Ethics professional from tech company or consultancy
- Regulatory attorney (GDPR/compliance specialist)
- Affected community representative (e.g., from bail system impact study)

---

## Course Policies

### Participation
Active participation in discussions and activities is expected. This includes both in-class contributions and engagement with peers on course projects.

### Academic Integrity
All work must be original. Proper attribution required for all sources. Discuss your ideas openly but complete individual work independently. Group projects require clear contribution documentation.

### Accessibility
Students with disabilities should notify the instructor early to arrange accommodations. See Disability Resources and Educational Services (DRES).

### Late Work
- Weekly reflections: up to 2 days late, 10% penalty
- Case analyses: 5 days late, 20% penalty
- Capstone project: no late submissions (fixed presentation date)

---

## Faculty Notes

### Teaching Philosophy
This course takes a **systems thinking** approach: AI governance isn't just about building better algorithms—it's about organizational structures, stakeholder incentives, regulatory environments, and human values. Students should see themselves as future business leaders who will shape how AI is governed.

### Key Pedagogical Strategies
1. **Case-driven:** Real-world examples ground ethical concepts
2. **Stakeholder-centered:** Multiple perspectives on governance
3. **Practical:** Students design actual governance frameworks
4. **Interactive:** Debates, audits, design workshops build critical thinking
5. **Relevant:** Regulatory and business examples stay current

### Common Student Misconceptions
- "AI governance is just compliance" → Emphasize strategic value (risk mitigation, competitive advantage, trust)
- "Fairness is a technical problem" → Highlight that fairness involves value tradeoffs, not just metrics
- "One size fits all" → Emphasize context-specificity of governance

### Instructor Preparation
- Week 1: Prepare ethical framework examples from current news
- Weeks 5-6: Update regulatory examples (AI Act, GDPR enforcement)
- Weeks 7-9: Collect recent case studies (1-2 weeks before class)
- Capstone: Identify 2-3 industry mentors to provide feedback

---

## Suggested Future Developments

**BADM 315 Advanced (400-level):**
- Deeper regulatory focus (GDPR, sector-specific rules)
- AI governance for global companies
- Ethics impact assessment methodology
- Capstone: Lead industry governance initiative

**Related Courses:**
- BADM 311: AI & Workforce Transformation
- BADM 300: Legal Environment (AI Liability focus)
- BADM 449/410: Business Strategy with AI component

---

*Course prepared: January 2026*
*For: Gies AI Curriculum Task Force*
*Part of: BADM Core Curriculum Evolution Strategy*
